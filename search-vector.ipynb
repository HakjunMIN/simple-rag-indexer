{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType, Vector\n",
    "\n",
    "load_dotenv()\n",
    "# Replace these with your own values, either in environment variables or directly here\n",
    "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\")\n",
    "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\") \n",
    "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\") \n",
    "AZURE_OPENAI_GPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_GPT_DEPLOYMENT\") or \"davinci\"\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\") or \"chat\"\n",
    "AZURE_OPENAI_EMB_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_EMB_DEPLOYMENT\") or \"embedding\"\n",
    "AZURE_SEARCH_SERVICE_KEY = os.environ.get(\"AZURE_SEARCH_SERVICE_KEY\") \n",
    "\n",
    "KB_FIELDS_CONTENT = os.environ.get(\"KB_FIELDS_CONTENT\") or \"content\"\n",
    "KB_FIELDS_CATEGORY = os.environ.get(\"KB_FIELDS_CATEGORY\") or \"category\"\n",
    "KB_FIELDS_SOURCEPAGE = os.environ.get(\"KB_FIELDS_SOURCEPAGE\") or \"sourcepage\"\n",
    "\n",
    "\n",
    "# Used by the OpenAI SDK\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2023-06-01-preview\"\n",
    "openai.api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\") \n",
    "# Comment these two lines out if using keys, set your API key in the OPENAI_API_KEY environment variable and set openai.api_type = \"azure\" instead\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# Set up clients for Cognitive Search and Storage\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=AzureKeyCredential(AZURE_SEARCH_SERVICE_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT uses a particular set of tokens to indicate turns in conversations\n",
    "prompt_prefix = \"\"\"<|im_start|>system\n",
    "어시스턴트는 에 정보가 충분하지 않은 경우에는 모른다고 말하검색 결과에서 나온 문서에 대한 질문을 도와줍니다. 답변은 간결하게 작성하세요.\n",
    "\n",
    "표 형식의 정보는 HTML 테이블로 반환합니다. 마크다운 형식은 반환하지 마세요.\n",
    "각 출처에는 이름 뒤에 콜론과 실제 정보가 있으며, 응답에 사용하는 각 사실에 대한 출처 이름을 항상 포함하세요. 소스를 참조할 때는 대괄호를 사용합니다(예: [info1.txt]). 소스를 결합하지 말고 각 소스를 개별적으로 나열합니다(예: [info1.txt][info2.pdf]).\n",
    "Sources:\n",
    "{sources}\n",
    "\n",
    "<|im_end|>\"\"\"\n",
    "\n",
    "turn_prefix = \"\"\"\n",
    "<|im_start|>user\n",
    "\"\"\"\n",
    "\n",
    "turn_suffix = \"\"\"\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompt_history = turn_prefix\n",
    "\n",
    "history = []\n",
    "\n",
    "summary_prompt_template = \"\"\"아래는 지금까지의 대화 요약과 사용자가 검색결과에서 검색하여 답변해야 하는 새로운 질문입니다. 대화와 새 질문을 기반으로 검색 쿼리를 생성합니다.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Search query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching: 인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "-------------------\n",
      "\n",
      "\n",
      "-------------------\n",
      "Prompt:\n",
      "<|im_start|>system\n",
      "어시스턴트는 에 정보가 충분하지 않은 경우에는 모른다고 말하검색 결과에서 나온 문서에 대한 질문을 도와줍니다. 답변은 간결하게 작성하세요.\n",
      "\n",
      "표 형식의 정보는 HTML 테이블로 반환합니다. 마크다운 형식은 반환하지 마세요.\n",
      "각 출처에는 이름 뒤에 콜론과 실제 정보가 있으며, 응답에 사용하는 각 사실에 대한 출처 이름을 항상 포함하세요. 소스를 참조할 때는 대괄호를 사용합니다(예: [info1.txt]). 소스를 결합하지 말고 각 소스를 개별적으로 나열합니다(예: [info1.txt][info2.pdf]).\n",
      "Sources:\n",
      "dbr_sample-0.pdf: PDF EditionTIMELESS INSIGHTDDBRDong-A Business Review dbr.donga.comDBR Case Study:인터넷형광펜에서AI서비스로성장한‘라이너(LINER)’ 검색정확 성높여준‘초개인화데이터’ 효과적리서치돕는AI툴로자리잡아저작권공지본PDF문서에실린글,그림,사진등저작권자가표시되어있지않은모든자료는발행사인㈜동아일보 사전동의없이는어떠한경우에도사용할수없습니다.사에저작권이있으며,무단전재재배포금지 본PDF문서는DBR독자및dbr.donga.com회원에게㈜동아일보사가제공하는것으로저작권법의보호를받습니다.㈜동아일보 사의허락없이PDF문서를온라인사이트등에무단게재,전재하거나유포할수없습니다.본파일중일부기능은제한될수있습니다.구독문의●개인구독문의: 02-6718-7802은행계좌:우리은행1005-801-116229㈜디유넷●단 체구독문의: 02-361-1506 은행계좌:국민은행009-01-1307-189㈜동아일보사동아일보사Downloaded by news123(DIGITAL), sh89.kang@kt.com, 2023-06-02 DBR Case Study:인터넷형광펜에서AI서비스로성장한‘라이너(LINER)’검색정확성높여준‘초개인화데이터’ 효과적리서치돕는AI툴로자리잡아이규열기자kylee@donga.comArticle at a Glance2015년형광펜기능을제공하는브라우저앱및브라우저확장프로그램으로출시된‘라 이너(LINER)’는사용자들의하이라이트데이터를토대로개인화된검색결과및콘텐츠 를큐레이션하는AI서비스로성장했다. GPT-4를적용한검색용챗봇‘라이너챗’은사용 자맞춤답변을내놓는다.라이너는‘가설공장’이라는자체적인프로세스를구축해2주 동안제품을개선할아이디어를개발,실험하며새로운기능을더해나갔다.별도의웹사이 트에접속할필요없이구글,네이버등기존의검색환경에서사용할수있도록설계한점 도편리성을더했다.라이너는해외사용자가90%에달하는글로벌서비스로전체MAU 는1000만명이상이다.미국,한국등에서는구독을,인도,동남아등에서는광고수익을 내세워국가별사용자특색에따른비즈니스모델을구축했다.\n",
      "Northwind_Standard_Benefits_Details-31.pdf: When purchasing or renting any home medical equipment, orthotics, prosthetics, or supplies, it is important to keep detailed records of all purchases or rentals. This includes keeping track of any receipts, invoices, or other documentation related to the purchase or rental. Additionally, it is important to keep track of any repair or maintenance services that are done on the item.Finally, it is important to note that the Northwind Standard plan does not cover the cost of any services or supplies that are provided outside the network of Northwind Health. If you choose to receive services or supplies from an out-of-network provider, you will be responsible for any costs associated with those services or supplies.By understanding the coverage of the Northwind Standard plan for Home Medical Equipment (HME), Orthotics, Prosthetics, and Supplies, you can ensure that you are taking full advantage of the benefits this plan offers. With the right knowledge and planning, you can make sure that you get the most out of your Northwind Standard plan.Hospice Care Hospice CareAt Contoso, we are proud to offer our employees access to Northwind Health’s \n",
      "dbr_sample-2.pdf: 올해4월에는GPT-4를적용 한인 공지능(AI)검색용챗봇‘라이너챗’을출시했 다.최신정보까지소스로활용하고사용자맞 춤으로답변을제공한다.라이너웹사이트나 앱에접속하지않아도검색포털과연동돼바로 활 용 할수있다는점도편리하다.검색결과페을저 이지에서텍스트를드래그하면해당내용 장할수도있고번역,추가검색도바로할수있 다.라이너앱이나웹사이트에서는자체적인 검색페이지와라이너챗,추천콘텐츠피드를 제공 한다.라이너가초개인화된추천서비스를제공할 수있는원천은사용 자들의‘형광펜’데이터다. 사실라이너자체가인터넷에서활 용가 능한형 광펜서비스로시작했다.책에서중요한부분 을형광펜으로표시하듯라이너는인터넷에서 도쓸수있는형광펜을만들었다.이를빅데이 터로활용해개인화된검색및추천서비스를 제공하며전세계1000만명이상의월간활성 화이용자수(MAU)를모았다.국내페이스북MAU(980만)와서울시전체인구(약943만명) 를웃도는수준이다.업무특성상강도높 은리 서치를하 는연구원,대학원생등이주사 용 자이며90%이상이미국,인도등글 로벌사 자다. 라이너가MAU 100만명에서1000만명까용지10배로성장하 과6개월이걸렸다. 100만명까지는마케팅없이유기적(organic) 으로성장했고2020년8월시리즈A투자를받 은이후에처음마케팅을시작하며급성장 을이 뤘다.최근일부스타트업이초고속성장을추 앙하면서도안정적인비즈니스모델은갖추지 못해자금난을겪고있는것과 는달리라이너는는데는불국가별사 용 자특성에따른비즈니스모델을구 축했다.그결과2022년9월스타트업혹한기 에도시리즈B투자를성공적으로마무리하며 110억원을확보했다.형광펜서비스로시작한라이너는어떻게초 개인화된AI서비스로도약할수있었을까.압 축성장을이루는동시에독자적인비즈니스 모델을갖추기까지어떤시행착오를거쳤을 까. DBR(동아비즈니스리뷰)이아우름플래닛 을창업하고현재는미국법인LINER Inc.의 대표를맡고있는김진우대표를만나경쟁력<table><tr><th>2017</th><th></th><th>2021</th><th></th><th>2023</th></tr><tr><td>~2019</td><td>2020</td><td>2021. 10</td><td>2022</td><td>2023.\n",
      "\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "인터넷 형광펜 서비스 '라이너(LINER)'는 사용자가 웹 페이지나 PDF 문서를 읽는 동안 중요한 내용을 형광펜으로 표시하여 저장하고, 이를 기반으로 개인화된 검색 및 컨텐츠 추천을 제공하는 인공지능 기반의 서비스입니다. \n",
      "\n",
      "라이너는 빅데이터와 인공지능 기술을 활용하여 사용자가 저장한 형광펜 정보를 분석하고, 사용자의 취향과 관심사를 파악하여 맞춤형 검색 및 컨텐츠 추천을 제공합니다. 또한 라이너 앱이나 웹 사이트에서는 자체적인 검색 페이지와 라이너챗, 추천 콘텐츠 피드를 제공합니다. \n",
      "\n",
      "라이너는 전 세계 1000만 명 이상의 월간 활성화 이용자를 보유하고 있으며, 국내외 연구원, 대학원생 등 강도 높은 리서치를 하는 사용자들이 사용하고 있습니다. 또한 미국, 한국 등에서는 구독을, 인도, 동남아 등에서는 광고 수익을 내세워 국가별 사용자 특색에 따른 비즈니스 모델을 구축하고 있습니다.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "인터넷 형광펜 서비스 '라이너(LINER)'는 사용자가 웹 페이지나 PDF 문서를 읽는 동안 중요한 내용을 형광펜으로 표시하여 저장하고, 이를 기반으로 개인화된 검색 및 컨텐츠 추천을 제공하는 인공지능 기반의 서비스입니다.\n",
      "\n",
      "라이너는 사용자가 저장한 형광펜 정보를 분석하여 사용자의 취향과 관심사를 파악하고, 맞춤형 검색 및 컨텐츠 추천을 제공합니다. 또한 라이너 앱이나 웹 사이트에서는 자체적인 검색 페이지와 라이너챗, 추천 콘텐츠 피드를 제공합니다.\n",
      "\n",
      "라이너는 전 세계 1000만 명 이상의 월간 활성화 이용자를 보유하고 있으며, 국내외 연구원, 대학원생 등 강도 높은 리서치를 하는 사용자들이 사용하고 있습니다. 또한 미국, 한국 등에서는 구독을, 인도, 동남아 등에서는 광고 수익을 내세워 국가별 사용자 특색에 따른 비즈니스 모델을 구축하고 있습니다.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "user: 인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "-------------------\n",
      "assistant: 인터넷 형광펜 서비스 '라이너(LINER)'는 사용자가 웹 페이지나 PDF 문서를 읽는 동안 중요한 내용을 형광펜으로 표시하여 저장하고, 이를 기반으로 개인화된 검색 및 컨텐츠 추천을 제공하는 인공지능 기반의 서비스입니다.\n",
      "\n",
      "라이너는 사용자가 저장한 형광펜 정보를 분석하여 사용자의 취향과 관심사를 파악하고, 맞춤형 검색 및 컨텐츠 추천을 제공합니다. 또한 라이너 앱이나 웹 사이트에서는 자체적인 검색 페이지와 라이너챗, 추천 콘텐츠 피드를 제공합니다.\n",
      "\n",
      "라이너는 전 세계 1000만 명 이상의 월간 활성화 이용자를 보유하고 있으며, 국내외 연구원, 대학원생 등 강도 높은 리서치를 하는 사용자들이 사용하고 있습니다. 또한 미국, 한국 등에서는 구독을, 인도, 동남아 등에서는 광고 수익을 내세워 국가별 사용자 특색에 따른 비즈니스 모델을 구축하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# Execute this cell multiple times updating user_input to accumulate chat history\n",
    "user_input = \"인터넷 형광펜 서비스 소개좀 부탁해요\"\n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "if len(history) > 0:\n",
    "    completion = openai.Completion.create(\n",
    "        engine=AZURE_OPENAI_GPT_DEPLOYMENT,\n",
    "        prompt=summary_prompt_template.format(summary=\"\\n\".join(history), question=user_input),\n",
    "        temperature=1,\n",
    "        max_tokens=32,\n",
    "        stop=[\"\\n\"])\n",
    "    search = completion.choices[0].text\n",
    "else:\n",
    "    search = user_input\n",
    "\n",
    "# Use Azure OpenAI to compute an embedding for the query\n",
    "query_vector = openai.Embedding.create(engine=AZURE_OPENAI_EMB_DEPLOYMENT, input=search)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "print(\"Searching:\", search)\n",
    "print(\"-------------------\")\n",
    "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "\n",
    "# Hybrid search with semantic search and vector reranking\n",
    "\n",
    "r = search_client.search(search, \n",
    "                         filter=filter,\n",
    "                         query_type=QueryType.SEMANTIC, \n",
    "                         query_language=\"en-us\", \n",
    "                         query_speller=\"lexicon\", \n",
    "                         semantic_configuration_name=\"default\", \n",
    "                         top=3,\n",
    "                         vector=Vector(value=query_vector, k=50, fields=\"embedding\") if query_vector else None)\n",
    "\n",
    "# Vector search only\n",
    "# r = search_client.search(search, top=3, vector=Vector(value=query_vector, k=50, fields=\"embedding\") if query_vector else None)\n",
    "\n",
    "results = [doc[KB_FIELDS_SOURCEPAGE] + \": \" + doc[KB_FIELDS_CONTENT].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "content = \"\\n\".join(results)\n",
    "\n",
    "prompt = prompt_prefix.format(sources=content) + prompt_history + user_input + turn_suffix\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "print(\"\\n-------------------\\nPrompt:\\n\" + prompt)\n",
    "\n",
    "completion = openai.Completion.create(\n",
    "    engine=AZURE_OPENAI_CHATGPT_DEPLOYMENT, \n",
    "    prompt=prompt, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024,\n",
    "    stop=[\"<|im_end|>\", \"<|im_start|>\"])\n",
    "\n",
    "prompt_history += user_input + turn_suffix + completion.choices[0].text + \"\\n<|im_end|>\" + turn_prefix\n",
    "history.append(\"user: \" + user_input)\n",
    "history.append(\"assistant: \" + completion.choices[0].text)\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

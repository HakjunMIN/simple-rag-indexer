{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType, Vector\n",
    "\n",
    "load_dotenv()\n",
    "# Replace these with your own values, either in environment variables or directly here\n",
    "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\")\n",
    "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\") \n",
    "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\") \n",
    "AZURE_OPENAI_GPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_GPT_DEPLOYMENT\") \n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\") \n",
    "AZURE_OPENAI_EMB_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_EMB_DEPLOYMENT\")\n",
    "AZURE_SEARCH_SERVICE_KEY = os.environ.get(\"AZURE_SEARCH_SERVICE_KEY\") \n",
    "\n",
    "KB_FIELDS_CONTENT = os.environ.get(\"KB_FIELDS_CONTENT\") or \"content\"\n",
    "KB_FIELDS_CATEGORY = os.environ.get(\"KB_FIELDS_CATEGORY\") or \"category\"\n",
    "KB_FIELDS_SOURCEPAGE = os.environ.get(\"KB_FIELDS_SOURCEPAGE\") or \"sourcepage\"\n",
    "\n",
    "\n",
    "# Used by the OpenAI SDK\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2023-06-01-preview\"\n",
    "openai.api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\") \n",
    "# Comment these two lines out if using keys, set your API key in the OPENAI_API_KEY environment variable and set openai.api_type = \"azure\" instead\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# Set up clients for Cognitive Search and Storage\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=AzureKeyCredential(AZURE_SEARCH_SERVICE_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT uses a particular set of tokens to indicate turns in conversations\n",
    "prompt_prefix = \"\"\"<|im_start|>system\n",
    "어시스턴트는 검색 결과에서 나온 문서에 대한 질문을 도와줍니다. 답변은 간결하게 작성하세요.\n",
    "Source에 나오지 않은 내용은 모른다고 대답합니다. Source결과에 나온 내용을 잘 읽어보세요.\n",
    "표 형식의 정보는 HTML 테이블로 반환합니다. 마크다운 형식은 반환하지 마세요.\n",
    "각 출처에는 이름 뒤에 콜론과 실제 정보가 있으며, 응답에 사용하는 각 사실에 대한 출처 이름을 항상 포함하세요. 소스를 참조할 때는 대괄호를 사용합니다(예: [info1.txt]). 소스를 결합하지 말고 각 소스를 개별적으로 나열합니다(예: [info1.txt][info2.pdf]).\n",
    "Sources:\n",
    "{sources}\n",
    "\n",
    "<|im_end|>\"\"\"\n",
    "\n",
    "turn_prefix = \"\"\"\n",
    "<|im_start|>user\n",
    "\"\"\"\n",
    "\n",
    "turn_suffix = \"\"\"\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompt_history = turn_prefix\n",
    "\n",
    "history = []\n",
    "\n",
    "summary_prompt_template = \"\"\"아래는 지금까지의 대화 요약과 사용자가 검색결과에서 검색하여 답변해야 하는 새로운 질문입니다. 대화와 새 질문을 기반으로 검색 쿼리를 생성합니다.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Search query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching: 인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "-------------------\n",
      "\n",
      "\n",
      "-------------------\n",
      "Prompt:\n",
      "<|im_start|>system\n",
      "어시스턴트는 검색 결과에서 나온 문서에 대한 질문을 도와줍니다. 답변은 간결하게 작성하세요.\n",
      "Source에 나오지 않은 내용은 모른다고 대답합니다. Source결과에 나온 내용을 잘 읽어보세요.\n",
      "표 형식의 정보는 HTML 테이블로 반환합니다. 마크다운 형식은 반환하지 마세요.\n",
      "각 출처에는 이름 뒤에 콜론과 실제 정보가 있으며, 응답에 사용하는 각 사실에 대한 출처 이름을 항상 포함하세요. 소스를 참조할 때는 대괄호를 사용합니다(예: [info1.txt]). 소스를 결합하지 말고 각 소스를 개별적으로 나열합니다(예: [info1.txt][info2.pdf]).\n",
      "Sources:\n",
      "dbr_sample-7.pdf: 예컨대,현재띄워져있는페이지의전체내용 을요약하거나핵 심내용및키워드를뽑아서제시할수있다.웹 페이지상텍스트를드래그하면하이라이트,번 역,쉽게이해하기,추가정보검색등의기능도 바로활 용 할수있다.김대표는“사용자들이찾아와야하는다른 서비스들과는달리사 용자들 을직접찾아가는 사 용 자경험을구축 한점이라이너의성장에크 게일조했다”며“현재는라이너앱과웹을찾아 오게만들기위해사 용 자경험(UX)과인터페이 스(UI)를개선하고있다”고설명했다.2주마다애자일하게스 크럼,끊임없이돌아가 는‘가설공 장’이처럼인터넷형광펜으로시작한라이너가다채로운기능 을갖추게된배경에는짧 은주기 (스프린트)로실험을반복하며점진적으로제품 을개선하는‘스크럼(Scrum)’형식의애자일 프로세스가있다.실리콘밸리에서1주일에1개 씩서비스를출시하던초기방식이현재는‘가 설공장’이라는라이너만의프로세스로자리 잡은것이다.라이너에선2주간의스프린트가진행되기전 에어떤가설을검증할지선정하는가설공장 미팅이진행된다.미팅에는CEO인김대표와 COS(Chief of Staff,최고보좌 관),프로덕트오 너(PO),데이터분석가(DA),디자이너가참여 한다.이들 은미팅에서1~2달에한번씩공유되 는전사목표를달성하기위한아이디어를제안 한다.이아이디어들은가설공장을돌리는원 료로비유된다.이때데이터에기반한정량적, 정성적근거들이함께제시돼야한다.이후실 제영향력을발휘할수있을것으로예상되거N 동아비즈니스리뷰Q回WW □ 이미지Q 지식iN8 인플루언서© 동영상DBR 홈페이지라이너 AI비즈니스 퍼슨의 필수 지식 DBR 경영전략부터 마케팅, 자기계발까지 15,000개 콘텐츠 무제한 월정액 서비스 첫달무료구독 , 베스트아티클동아비즈니스리뷰는 2008년 1월 15일 창간된 경영 전문 매거진으로 경영 뿐만 아니라 마케팅 전략, 리더십, 인 문학 등 강영 관련 분야 지식을 제공하는 매거진입니다. 또한, 약 1.5만 명의 팔로워를 보유하고 있으며, 매일 까 다로운 문제들에 대한 해결책을 제공하는 포스트가 약 1 천 건 정도 게시되어 있습니다. 동아비즈니스리뷰는 DBR 비즈니스 리더의 프리미엄 솔루션을 제공하고 있으 며, 다양한 학습형 멀티미디어 큰렌즈로 구성된 온라인 경영 지식 정보 서비스도 제공하고 있습니다.\n",
      "dbr_sample-2.pdf: 올해4월에는GPT-4를적용 한인 공지능(AI)검색용챗봇‘라이너챗’을출시했 다.최신정보까지소스로활용하고사용자맞 춤으로답변을제공한다.라이너웹사이트나 앱에접속하지않아도검색포털과연동돼바로 활 용 할수있다는점도편리하다.검색결과페을저 이지에서텍스트를드래그하면해당내용 장할수도있고번역,추가검색도바로할수있 다.라이너앱이나웹사이트에서는자체적인 검색페이지와라이너챗,추천콘텐츠피드를 제공 한다.라이너가초개인화된추천서비스를제공할 수있는원천은사용 자들의‘형광펜’데이터다. 사실라이너자체가인터넷에서활 용가 능한형 광펜서비스로시작했다.책에서중요한부분 을형광펜으로표시하듯라이너는인터넷에서 도쓸수있는형광펜을만들었다.이를빅데이 터로활용해개인화된검색및추천서비스를 제공하며전세계1000만명이상의월간활성 화이용자수(MAU)를모았다.국내페이스북MAU(980만)와서울시전체인구(약943만명) 를웃도는수준이다.업무특성상강도높 은리 서치를하 는연구원,대학원생등이주사 용 자이며90%이상이미국,인도등글 로벌사 자다. 라이너가MAU 100만명에서1000만명까용지10배로성장하 과6개월이걸렸다. 100만명까지는마케팅없이유기적(organic) 으로성장했고2020년8월시리즈A투자를받 은이후에처음마케팅을시작하며급성장 을이 뤘다.최근일부스타트업이초고속성장을추 앙하면서도안정적인비즈니스모델은갖추지 못해자금난을겪고있는것과 는달리라이너는는데는불국가별사 용 자특성에따른비즈니스모델을구 축했다.그결과2022년9월스타트업혹한기 에도시리즈B투자를성공적으로마무리하며 110억원을확보했다.형광펜서비스로시작한라이너는어떻게초 개인화된AI서비스로도약할수있었을까.압 축성장을이루는동시에독자적인비즈니스 모델을갖추기까지어떤시행착오를거쳤을 까. DBR(동아비즈니스리뷰)이아우름플래닛 을창업하고현재는미국법인LINER Inc.의 대표를맡고있는김진우대표를만나경쟁력<table><tr><th>2017</th><th></th><th>2021</th><th></th><th>2023</th></tr><tr><td>~2019</td><td>2020</td><td>2021. 10</td><td>2022</td><td>2023.\n",
      "dbr_sample-3.pdf: 이중칭찬릴레이커뮤니티‘티키타카’ , 간단하게자료 를전달 하 는클라 우 드‘아이센드’ 등8개서비스 를론칭했다.은라이너는그중3번째서비스다.김대표는평소활 자중 독수준으로읽을것을늘손에쥐고 있었다.그러다중요한내용을발견하면바로 바지에서형광펜을꺼내줄을그었다.김대표 는인터넷에는형광펜이없는게늘아쉬웠다. 검색시장에도불편함을느꼈다.과제를위해 검색하다상위에뜬페이지를살펴봐도원하 정보가없는경우가허다했다.문득누군가정는 말중요한정보를형광펜으로표시해주면좋겠 다는생각을했다.그러기위해선우선인터넷 에서사 할수있는형광펜이필요했다. 용그렇게2015년7월형광펜기능이탑재된 iOS브라우저앱‘라이너’를만들었다.브라우79 DBR No. 370Downloaded by news123(DIGITAL), sh89.kang@kt.com, 2023-06-02 출처:동아닷컴캡처구글웹스토어,마이크로소프트엣지추가기능페이지에서라이너를설치하고,저장하고싶은텍스트를 드래그하면형광펜기능이활성화된다.여러색을적용해정보의유형,중요도등을구분하고,해당정보는 라이너웹사이트,앱에서모아볼수있다저에서정보를탐색하다중요한텍스트를드래 그하면형광펜버튼이활성화되는식이다.하 이라이트한정보들 는을한데모아다시검색하 불편함없이찾아볼수있게했다.사실라이너 에는큰기대가없었다.너무단순한아이디어 라사업이될지의문이었다.그러나시장의반 응 은달랐다.출시첫날에400건이다운로드됐 다.반짝사람들의관심을끈줄알았는데출시 한달만5000건을달성했다.라이너의가능성 이입증된것이다.라이너의다음미션은꾸준히앱을찾 는사 용자의비율,즉사 용 자유지율(리텐션)을높게유 지하는것이었다.다운로드한사람은많은데 상사막 용하는이가없다면‘유령앱’이나다름없다.보통사 용 용 자유지 자수가적을때는사율이높게나타난다.사용목적이뚜렷한이용 자들이얼리어댑터로유입되기때문이다.꾸준용 자유지율 을끌어올 히몸집을키우면서도사려야충성도높 은사용자들 을바탕으로비즈니스모델도접목 할수있다.사 람 들이매일라이너를찾게만 들 기위해택한 름아닌데스것은다 크 톱중 심제품 으 로의전환이 다.라이너를처음출 시한지2달만에구 글 의브라장프로그램버전을출시했다.\n",
      "\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "user: 인터넷 형광펜 서비스 소개좀 부탁해요\n",
      "-------------------\n",
      "assistant: 라이너(Liner)는 인터넷에서 형광펜을 사용할 수 있는 서비스입니다. 웹사이트나 앱에서 텍스트를 드래그하면 형광펜 기능이 활성화되어 해당 부분을 강조할 수 있습니다. 또한, 강조한 내용을 한 곳에 모아서 다시 검색하거나 정리할 수 있는 기능도 제공합니다. 라이너는 검색 시장에서 불편함을 느꼈던 창업자가 시작한 서비스로, 현재는 AI 검색용 챗봇 '라이너챗' 등 다양한 서비스를 제공하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# Execute this cell multiple times updating user_input to accumulate chat history\n",
    "user_input = \"인터넷 형광펜 서비스 소개좀 부탁해요\"\n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "if len(history) > 0:\n",
    "    completion = openai.Completion.create(\n",
    "        engine=AZURE_OPENAI_GPT_DEPLOYMENT,\n",
    "        prompt=summary_prompt_template.format(summary=\"\\n\".join(history), question=user_input),\n",
    "        temperature=1,\n",
    "        max_tokens=32,\n",
    "        stop=[\"\\n\"])\n",
    "    search = completion.choices[0].text\n",
    "else:\n",
    "    search = user_input\n",
    "\n",
    "# Use Azure OpenAI to compute an embedding for the query\n",
    "query_vector = openai.Embedding.create(engine=AZURE_OPENAI_EMB_DEPLOYMENT, input=search)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "print(\"Searching:\", search)\n",
    "print(\"-------------------\")\n",
    "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "\n",
    "# 1. only semantic search\n",
    "\n",
    "# r = search_client.search(search, \n",
    "#                          filter=filter,\n",
    "#                          query_type=QueryType.SEMANTIC, \n",
    "#                          query_language=\"en-us\", \n",
    "#                          query_speller=\"lexicon\", \n",
    "#                          semantic_configuration_name=\"default\", \n",
    "#                          top=3)\n",
    "\n",
    "# 2. Hybrid search with semantic search and vector reranking\n",
    "\n",
    "# r = search_client.search(search, \n",
    "#                          filter=filter,\n",
    "#                          query_type=QueryType.SEMANTIC, \n",
    "#                          query_language=\"en-us\", \n",
    "#                          query_speller=\"lexicon\", \n",
    "#                          semantic_configuration_name=\"default\", \n",
    "#                          top=3,\n",
    "#                          vector=query_vector, \n",
    "#                          top_k=50 if query_vector else None, \n",
    "#                          vector_fields=\"embedding\" if query_vector else None)\n",
    "\n",
    "# 3. Vector search only\n",
    "r = search_client.search(search, top=3, vector=query_vector, top_k=50 if query_vector else None, vector_fields=\"embedding\" if query_vector else None)\n",
    "\n",
    "results = [doc[KB_FIELDS_SOURCEPAGE] + \": \" + doc[KB_FIELDS_CONTENT].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "content = \"\\n\".join(results)\n",
    "\n",
    "prompt = prompt_prefix.format(sources=content) + prompt_history + user_input + turn_suffix\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "print(\"\\n-------------------\\nPrompt:\\n\" + prompt)\n",
    "\n",
    "completion = openai.Completion.create(\n",
    "    engine=AZURE_OPENAI_CHATGPT_DEPLOYMENT, \n",
    "    prompt=prompt, \n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    "    stop=[\"<|im_end|>\", \"<|im_start|>\"])\n",
    "\n",
    "prompt_history += user_input + turn_suffix + completion.choices[0].text + \"\\n<|im_end|>\" + turn_prefix\n",
    "history.append(\"user: \" + user_input)\n",
    "history.append(\"assistant: \" + completion.choices[0].text)\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
